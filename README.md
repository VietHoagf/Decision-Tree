# Decision Tree, Bagging, Random Forest, and Boosting - CS115 Final Project

## Introduction
This is the final project for Group 8 in the CS115 course. Our project focuses on exploring and implementing machine learning algorithms, including **Decision Tree, Bagging, Random Forest, and Boosting**, to solve real-world prediction problems. We applied these techniques to two datasets: one for predicting house prices and another for detecting heart disease.

## Team Members
- **Nguyễn Hải Đăng** - 23520228  
- **Đoàn Việt Hoàng** - 23520515  
- **Nguyễn Vũ Khang** - 23520701  
- **Lê Minh Kha** - 23520664  
- **Trần Quang Minh** - 23520958  

## Datasets
We utilized the following datasets for our project:
1. **[Housing Prediction](https://drive.google.com/file/d/1C9RYDB8l_0GZF4PYRoOmaIKSDZxaDAle/view?usp=share_link)**  
   - **Purpose**: Predict house prices based on various features (e.g., size, location, number of rooms).  
   - **Source**: Kaggle
2. **[Heart Disease](https://drive.google.com/file/d/1Rdb6PWmwhLKwdCX-joWKZvCqy3QBy0Nz/view?usp=share_link)**  
   - **Purpose**: Predict whether a person has heart disease based on health-related indices (e.g., cholesterol levels, blood pressure).  
   - **Source**: Kaggle

## Objectives
- Understand the theoretical foundations of Decision Trees and ensemble methods (Bagging, Random Forest, Boosting).
- Implement these algorithms using Python and evaluate their performance on the provided datasets.
- Compare the effectiveness of each method in terms of accuracy, robustness, and computational efficiency.

## Technologies Used
- **Programming Language**: Python  
- **Libraries**: `scikit-learn`, `pandas`, `numpy`, `matplotlib`  
- **Tools**: Jupyter Notebook, Google Colab 

